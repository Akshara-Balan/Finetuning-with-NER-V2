{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10969433,"sourceType":"datasetVersion","datasetId":6825282}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForTokenClassification,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForTokenClassification\n)\nimport torch\nimport ast  # To safely convert string representation of lists back to Python lists\n\n# Load dataset\ndataset = load_dataset(\"AksharaBalan/malayalam-ner-dataset-naamapadam\")\n\n# Manually create a validation split (10% for validation)\ndataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\ndataset[\"validation\"] = dataset.pop(\"test\")\n\n# Print dataset info\nprint(dataset)\nprint(dataset[\"train\"][0])\n\n# Load model and tokenizer\nmodel_name = \"l3cube-pune/malayalam-bert\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Automatically determine number of labels\nunique_labels = set()\nfor row in dataset[\"train\"]:\n    unique_labels.update(ast.literal_eval(row[\"ner_tags\"]))\nnum_labels = len(unique_labels)\n\n# Load model with correct label size\nmodel = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n\ndef tokenize_and_align_labels(examples):\n    # Convert string representations back to lists\n    examples[\"tokens\"] = [ast.literal_eval(x) for x in examples[\"tokens\"]]\n    examples[\"ner_tags\"] = [ast.literal_eval(x) for x in examples[\"ner_tags\"]]\n\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128,\n        is_split_into_words=True\n    )\n\n    all_labels = []\n    for i in range(len(examples[\"tokens\"])):  # Loop through each example\n        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Get word IDs\n        label_ids = []\n        for word_id in word_ids:\n            if word_id is None:\n                label_ids.append(-100)  # Ignore special tokens\n            else:\n                label_ids.append(examples[\"ner_tags\"][i][word_id])  # Assign label\n        \n        all_labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = all_labels\n    return tokenized_inputs\n\n# Apply tokenization\ntokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n\n# Data collator\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./malayalam-ner-finetuned\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    push_to_hub=True,  # Enable model pushing\n    hub_model_id=\"AksharaBalan/malayalam-bert-finetuned-ner\",\n    report_to=\"none\"  # Disabling WandB logging\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\n# Start Fine-Tuning\ntrainer.train()\n\n# Save and push the model\nmodel.save_pretrained(\"./malayalam-ner-finetuned\")\ntokenizer.save_pretrained(\"./malayalam-ner-finetuned\")\ntrainer.push_to_hub()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:35:12.946302Z","iopub.execute_input":"2025-03-10T06:35:12.946637Z","iopub.status.idle":"2025-03-10T07:41:42.177391Z","shell.execute_reply.started":"2025-03-10T06:35:12.946611Z","shell.execute_reply":"2025-03-10T07:41:42.176509Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 45000\n    })\n    validation: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 5000\n    })\n})\n{'tokens': \"['‡¥Ö‡¥®‡¥®‡µç‡¥§‡µç', '‡¥®‡¥æ‡¥ó‡¥ø', '‡µÜ‡¥≤', '‡¥Ö‡¥ö‡¥¨‡µΩ', '‡¥ö‡µå‡¥ï‡µç‡¥ï‡¥ø‡µΩ', '‡¥ï‡µç‡¥∞‡¥Æ‡¥∏‡¥Æ‡¥æ‡¥ß‡¥æ‡¥®', '‡¥ö‡µÅ‡¥Æ‡¥§‡¥≤‡¥Ø‡µÅ‡¥£‡µç‡¥ü‡¥æ‡¥Ø‡¥ø‡¥∞‡µÅ‡¥®‡µç‡¥®', '‡¥∏‡¥ø', '.', '‡¥Ü‡µº', '.', '‡¥™‡¥ø', '.', '‡¥é‡¥´‡µç', '‡¥∏‡¥Ç‡¥ò‡¥§‡µç‡¥§‡¥ø‡¥®‡µÅ', '‡¥®‡µá‡¥∞‡µÜ', '‡¥§‡µÄ‡¥µ‡µç‡¥∞‡¥µ‡¥æ‡¥¶‡¥ø‡¥ï‡µæ', '‡¥µ‡µÜ‡¥ü‡¥ø‡¥Ø‡µÅ‡¥§‡¥ø‡µº‡¥ï‡µç‡¥ï‡µÅ‡¥ï‡¥Ø‡¥æ‡¥Ø‡¥ø‡¥∞‡µÅ‡¥®‡µç‡¥®‡µÅ', '.']\", 'ner_tags': '[0, 5, 0, 5, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'}\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at l3cube-pune/malayalam-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0db959ba133249af856d6b2860e1039a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c31beaffca44776a01b77977f2df381"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-17-155007cfabc8>:89: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8439' max='8439' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8439/8439 1:05:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.345500</td>\n      <td>0.371150</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.323000</td>\n      <td>0.337661</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.267600</td>\n      <td>0.339289</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nNo files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AksharaBalan/malayalam-bert-finetuned-ner/commit/ba8ad85b34643c7051fea91fdb1a60a445ab00b6', commit_message='End of training', commit_description='', oid='ba8ad85b34643c7051fea91fdb1a60a445ab00b6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/AksharaBalan/malayalam-bert-finetuned-ner', endpoint='https://huggingface.co', repo_type='model', repo_id='AksharaBalan/malayalam-bert-finetuned-ner'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Save and push the model\nmodel.save_pretrained(\"./malayalam-ner-finetuned-bert\")\ntokenizer.save_pretrained(\"./malayalam-ner-finetuned-bert\")\ntrainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:41:42.178488Z","iopub.execute_input":"2025-03-10T07:41:42.178719Z","iopub.status.idle":"2025-03-10T07:41:51.153644Z","shell.execute_reply.started":"2025-03-10T07:41:42.178699Z","shell.execute_reply":"2025-03-10T07:41:51.152970Z"}},"outputs":[{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AksharaBalan/malayalam-bert-finetuned-ner/commit/ba8ad85b34643c7051fea91fdb1a60a445ab00b6', commit_message='End of training', commit_description='', oid='ba8ad85b34643c7051fea91fdb1a60a445ab00b6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/AksharaBalan/malayalam-bert-finetuned-ner', endpoint='https://huggingface.co', repo_type='model', repo_id='AksharaBalan/malayalam-bert-finetuned-ner'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"**TAKING INFERENCE**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n\n# Model checkpoint from Hugging Face\nmodel_name = \"AksharaBalan/malayalam-bert-finetuned-ner\"\n\n# Load model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\n\n# Load NER pipeline\nner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:42:45.453274Z","iopub.execute_input":"2025-03-10T07:42:45.453569Z","iopub.status.idle":"2025-03-10T07:42:51.806863Z","shell.execute_reply.started":"2025-03-10T07:42:45.453547Z","shell.execute_reply":"2025-03-10T07:42:51.806186Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80af5ca498004579b82cac2a7ec958d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4406ac33ad04d6f971b9c7abd7d2d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/6.41M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d852bcdfc10b4e48b28d67c53ec73540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41cf038e61fc49a087afb957d1ffea77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/981 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716b07aafb134977a496277b87519c75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/948M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b259df09d6f4bd387e0680439dfabfc"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"sample_text = \"‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥æ‡¥§‡¥æ‡¥∞‡¥Ç ‡¥Æ‡µã‡¥π‡µª‡¥≤‡¥æ‡µΩ, ‡¥™‡µç‡¥∞‡¥∂‡¥∏‡µç‡¥§‡¥®‡¥æ‡¥Ø ‡¥®‡¥ü‡µª ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ü‡µç‡¥ü‡¥ø‡¥Ø‡µã‡¥ü‡µä‡¥™‡µç‡¥™‡¥Ç ‡¥ï‡µä‡¥ö‡µç‡¥ö‡¥ø‡¥Ø‡¥ø‡¥≤‡µÜ ‡¥≤‡µÅ‡¥≤‡µÅ‡¥Æ‡¥æ‡¥≥‡¥ø‡µΩ ‡¥è‡¥∑‡µç‡¥Ø‡¥æ‡¥®‡µÜ‡¥±‡µç‡¥±‡µç ‡¥®‡µç‡¥Ø‡µÇ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ ‡¥Ö‡¥≠‡¥ø‡¥Æ‡µÅ‡¥ñ‡¥§‡µç‡¥§‡¥ø‡µΩ ‡¥™‡¥ô‡µç‡¥ï‡µÜ‡¥ü‡µÅ‡¥§‡µç‡¥§‡µÅ.\"\n\n# Get NER predictions\npredictions = ner_pipeline(sample_text)\n\n# Print results\nfor entity in predictions:\n    print(f\"Entity: {entity['word']}, Label: {entity['entity_group']}, Score: {entity['score']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:49:54.703205Z","iopub.execute_input":"2025-03-10T07:49:54.703529Z","iopub.status.idle":"2025-03-10T07:49:54.723878Z","shell.execute_reply.started":"2025-03-10T07:49:54.703504Z","shell.execute_reply":"2025-03-10T07:49:54.723244Z"}},"outputs":[{"name":"stdout","text":"Entity: ‡¥∏‡¥ø‡¥®‡¥ø‡¥Æ‡¥æ‡¥§‡¥æ‡¥∞‡¥Ç, Label: LABEL_0, Score: 0.9922\nEntity: ‡¥Æ‡µã‡¥π‡µª‡¥≤‡¥æ‡µΩ, Label: LABEL_1, Score: 0.9534\nEntity: , ‡¥™‡µç‡¥∞‡¥∂‡¥∏‡µç‡¥§‡¥®‡¥æ‡¥Ø ‡¥®‡¥ü‡µª, Label: LABEL_0, Score: 0.9923\nEntity: ‡¥Æ‡¥Æ‡µç‡¥Æ‡µÇ‡¥ü‡µç‡¥ü‡¥ø‡¥Ø‡µã‡¥ü‡µä‡¥™‡µç‡¥™‡¥Ç, Label: LABEL_1, Score: 0.8746\nEntity: ‡¥ï‡µä‡¥ö‡µç‡¥ö‡¥ø‡¥Ø‡¥ø‡¥≤‡µÜ ‡¥≤‡µÅ‡¥≤‡µÅ‡¥Æ‡¥æ‡¥≥‡¥ø‡µΩ, Label: LABEL_0, Score: 0.7634\nEntity: ‡¥è‡¥∑‡µç‡¥Ø‡¥æ‡¥®‡µÜ‡¥±‡µç‡¥±‡µç, Label: LABEL_3, Score: 0.7398\nEntity: ‡¥®‡µç‡¥Ø‡µÇ‡¥∏‡¥ø‡¥®‡µç‡¥±‡µÜ, Label: LABEL_4, Score: 0.4759\nEntity: ‡¥Ö‡¥≠‡¥ø‡¥Æ‡µÅ‡¥ñ‡¥§‡µç‡¥§‡¥ø‡µΩ ‡¥™‡¥ô‡µç‡¥ï‡µÜ‡¥ü‡µÅ‡¥§‡µç‡¥§‡µÅ., Label: LABEL_0, Score: 0.9943\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Get label mappings from the model\nlabel_mapping = model.config.id2label\nprint(label_mapping)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T07:46:28.765352Z","iopub.execute_input":"2025-03-10T07:46:28.765641Z","iopub.status.idle":"2025-03-10T07:46:28.769827Z","shell.execute_reply.started":"2025-03-10T07:46:28.765619Z","shell.execute_reply":"2025-03-10T07:46:28.769018Z"}},"outputs":[{"name":"stdout","text":"{0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3', 4: 'LABEL_4', 5: 'LABEL_5', 6: 'LABEL_6'}\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}